{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отзывы для обучения уже загружены скриптом в SQLite3 бд.\n",
    "\n",
    "Часть данных была вручную размечена для улучшения качества. Эти датасеты не включены в репозиторий, однако я готов ими поделиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import html\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Плюсы: Хорошая камера, получаются четкие снимк...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Плюсы: Это мой четвертый Xiaomi, один лучше др...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Плюсы: безрамочный, цвета оч. сочные, камера 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Плюсы: Мощный процессор, 6 Gb памяти, отличная...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Плюсы: Яркий экран, отличное качество фото. Ми...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  Плюсы: Хорошая камера, получаются четкие снимк...      1\n",
       "1           1  Плюсы: Это мой четвертый Xiaomi, один лучше др...      1\n",
       "2           2  Плюсы: безрамочный, цвета оч. сочные, камера 6...      1\n",
       "3           3  Плюсы: Мощный процессор, 6 Gb памяти, отличная...      1\n",
       "4           4  Плюсы: Яркий экран, отличное качество фото. Ми...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./train_data.csv\")\n",
    "train_data[\"label\"] = train_data[\"label\"].map({\"pos\":1,\"neg\":0})\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Подготовка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я буду использовать два варианта: довольно стерильные наборы слов и +- оригинальные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import _VectorizerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class RoughPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, data, y=None):\n",
    "        return list(map(self.normalize_text_re, map(self.normalize_text, data)))\n",
    "    \n",
    "    def normalize_text(self, text):\n",
    "        _t = html.unescape(text)\n",
    "        _t = _t.replace(\"Плюсы: \",\". \")\n",
    "        _t = _t.replace(\"Минусы: \",\". \")\n",
    "        _t = _t.replace(\"Впечатления: \",\". \")\n",
    "        _t = _t.replace(\"<p>\",\" \")\n",
    "        _t = _t.replace(\"</p>\", \" \")\n",
    "        _t = _t.replace(\"\\n\", \" \")\n",
    "        _t = _t.replace(\"\\r\", \" \")\n",
    "        _t = _t.replace(\"\\t\", \" \")\n",
    "        _t = _t.replace('\"', \" \")\n",
    "        _t = _t.lower()\n",
    "        return _t.strip()\n",
    "    \n",
    "    def normalize_text_re(self, text):\n",
    "        _t = text\n",
    "        _t = re.sub(r\"[\\s.,\\-\\+><;:!?()]\", \" \", _t)\n",
    "        _t = re.sub(r\"\\s+\", \" \", _t)\n",
    "        return _t.strip()\n",
    "    \n",
    "    def fit(self, data, y=None):\n",
    "        return self.fit_transform(data)\n",
    "    \n",
    "    def transform(self, data, y=None):\n",
    "        return self.fit_transform(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy препроцессор, чтоб проще пайплайн строить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, data, y=None):\n",
    "        return data\n",
    "    \n",
    "    def transform(self, data, y=None):\n",
    "        return data\n",
    "    \n",
    "    def fit(self, data, y=None):\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я хочу воспользоваться библиотекой gensim, потому что я уже использовал их эмбеддинги, и они отлично показали себя в классификации, даже на плохо обработанном датасете.\n",
    "\n",
    "Чтобы потом удобно запаковать это в sklearn pipeline, я реализую свой класс по образу `TfIdfVectorizer` из `sklearn.feature_extraction`\n",
    "\n",
    "Также я попробую TfIdfVectorizer и CountVectorizer сам по себе для сравнения какой лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import doc2vec\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "\n",
    "class GensimVectorizer(_VectorizerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        X = self.preprocess(raw_documents)\n",
    "        # print(\"Creating model...\")\n",
    "        model = gensim.models.doc2vec.Doc2Vec(\n",
    "            vector_size=100, \n",
    "            min_count=10,\n",
    "            epochs=40\n",
    "        )\n",
    "        # print(\"Building vocab...\")\n",
    "        model.build_vocab(X)\n",
    "        # print(\"Training doc2vec...\")\n",
    "        model.train(X, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "        self.model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, raw_documents, y=None):\n",
    "        X = self.preprocess(raw_documents)\n",
    "        # print(\"Iinferring vectors...\")\n",
    "        vectorized_texts = []\n",
    "        for doc_id, _ in enumerate(tqdm(X, desc=\"Inferring vectors: \")):\n",
    "            inferred_vector = self.model.infer_vector(X[doc_id].words)\n",
    "            vectorized_texts.append(inferred_vector)\n",
    "\n",
    "        return vectorized_texts\n",
    "\n",
    "    def preprocess(self, raw_documents):\n",
    "        # print(\"Tokenization...\")\n",
    "        processed_texts = []\n",
    "        for idx, text in enumerate(tqdm(raw_documents, desc=\"Tokenization: \")):\n",
    "            processed_texts.append(doc2vec.TaggedDocument(simple_preprocess(text), [idx]))\n",
    "        return processed_texts\n",
    "\n",
    "\n",
    "    def fit_transform(self, texts, y=None) -> np.ndarray:\n",
    "        self.fit(texts)\n",
    "        X = self.transform(texts)\n",
    "        \n",
    "        return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обучение модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели, которые я буду рассматривать:\n",
    "+ LogisticRegression\n",
    "+ GradientBoosting\n",
    "+ LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "# y = data.label.map({\"pos\": 1, \"neg\": 0})\n",
    "y = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "_model = make_pipeline(DummyPreprocessor(), CountVectorizer(ngram_range=(1,2)), LinearSVC(max_iter=4000, class_weight=\"balanced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('dummypreprocessor',\n",
       "                 <__main__.DummyPreprocessor object at 0x7f391c33f790>),\n",
       "                ('countvectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('linearsvc',\n",
       "                 LinearSVC(class_weight='balanced', max_iter=4000))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88442211, 0.85678392, 0.85678392, 0.8790932 ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(_model, X, y, n_jobs=6, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Улучшение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить модель можно несколькими путями:\n",
    "+ 1. Попробовать разный препроцессинг текста\n",
    "+ 2. Подобрать параметры модели векторизации\n",
    "+ 3. Подобрать параметры классификатора\n",
    "+ 4. Попробовать другие классификаторы\n",
    "+ 5. Сбалансировать классы для обучения\n",
    "+ 0. Делать перебор не по сетке, а более \"разумными\" методами\n",
    "\n",
    "Я сделаю только пп. 1, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_ = Pipeline([\n",
    "    (\"preprocessor\", RoughPreprocessor()),\n",
    "    (\"vec\", GensimVectorizer()),\n",
    "    (\"clf\", GradientBoostingClassifier())\n",
    "])\n",
    "# я разбил на несколько словарей потому что \n",
    "# параметры не унифицированы между классами моделей\n",
    "linear_classifiers = {\n",
    "    \"clf\":[LogisticRegression(), LinearSVC()],\n",
    "    \"clf__class_weight\":[\"balanced\"],\n",
    "    \"clf__dual\": [True, False]\n",
    "}\n",
    "forest_classifiers = {\n",
    "    \"clf\":[GradientBoostingClassifier(), RandomForestClassifier()],\n",
    "    \"clf__n_estimators\":[100,200, 500],\n",
    "    \"clf__max_depth\": [3,4,5,10,20],\n",
    "}\n",
    "preprocessors = {\n",
    "    \"preprocessor\":[RoughPreprocessor(), DummyPreprocessor()],\n",
    "}\n",
    "common_vectorizers = {\n",
    "    \"vec\": [CountVectorizer(), TfidfVectorizer()],\n",
    "    \"vec__ngram_range\": [(1,1), (1,2), (1,3), (1,4), (1,5)],\n",
    "    \"vec__min_df\": [1,2,3,4,10],\n",
    "    \"vec__max_features\": [None, 200, 500, 1000]\n",
    "}\n",
    "embedding_vectorizers = {\n",
    "    \"vec\": [GensimVectorizer()]\n",
    "}\n",
    "\n",
    "param_grid = [\n",
    "{\n",
    "    # Plain Vectorizers + Linear Models\n",
    "    **preprocessors,\n",
    "    **common_vectorizers,\n",
    "    **linear_classifiers    \n",
    "}, \n",
    "{\n",
    "    # Gensim Embeddings + Linear Models\n",
    "    **preprocessors,\n",
    "    **embedding_vectorizers,\n",
    "    **linear_classifiers,\n",
    "}, \n",
    "{\n",
    "    # Gensim Embeddings + GradBoost Models\n",
    "    **preprocessors,\n",
    "    **embedding_vectorizers,\n",
    "    **forest_classifiers,\n",
    "}, \n",
    "{\n",
    "    # Plain Vectorizers + GradBoost Models\n",
    "    **preprocessors,\n",
    "    **common_vectorizers,\n",
    "    **forest_classifiers,\n",
    "}\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ~ несколько недель на 6 ядрах Ryzen3\n",
    "gscv_ = GridSearchCV(\n",
    "    estimator=pipeline_,\n",
    "    param_grid=param_grid, \n",
    "    scoring=\"accuracy\", \n",
    "    n_jobs=6, refit=True, cv=3, verbose=2)\n",
    "gscv_.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8680074382025134\n",
      "{'clf': LinearSVC(class_weight='balanced'), 'clf__class_weight': 'balanced', 'clf__dual': True, 'preprocessor': <__main__.DummyPreprocessor object at 0x7f82589ecd60>, 'vec': CountVectorizer(min_df=2, ngram_range=(1, 4)), 'vec__min_df': 2, 'vec__ngram_range': (1, 4)}\n"
     ]
    }
   ],
   "source": [
    "print(gscv_.best_score_)\n",
    "print(gscv_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший набор параметров:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = gscv_.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = _model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Инференс и подготовка сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-77a271d2be4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrevs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "# это для импорта предоставленного файла\n",
    "import bs4\n",
    "test = []\n",
    "with open(\"test.csv\") as tfile:\n",
    "    sp = bs4.BeautifulSoup(tfile)\n",
    "    revs = sp.findAll(\"review\")\n",
    "    for r in revs:\n",
    "        test.append(r.text)\n",
    "\n",
    "# pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# а это мой размеченный тестовый файл\n",
    "test = pd.read_csv(\"./test_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"prediction\"] = model_final.predict(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# моя разметка тестового файла не очень точная.\n",
    "accuracy_score(test[\"y\"], test[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy()\n",
    "submission[\"y\"] = test.prediction.map({1: \"pos\", 0: \"neg\"})\n",
    "submission.to_csv(\"./submission.csv\", columns=[\"y\"], index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Упаковка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В финальный пайп я пакую предобученную на большой выборке модель векторизации \n",
    "# и классификатор, обученный на выборке после ресемплинга\n",
    "final_pipeline = model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../SentimentModelRU.pkl\", \"wb\") as fout:\n",
    "    dill.dump(final_pipeline, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../SentimentModelRU.pkl\", \"rb\") as fin:\n",
    "    v = dill.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
