{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отзывы для обучения уже загружены скриптом в SQLite3 бд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import html\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('reviews_363.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(c.execute(\"SELECT * FROM reviews;\"))\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(train_data, columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text label\n",
       "0  <p>Хорошая камера, получаются четкие снимки в ...   pos\n",
       "1  <p>Это мой четвертый Xiaomi, один лучше другог...   pos\n",
       "2  безрамочный, цвета оч. сочные, камера 64, откл...   pos\n",
       "3  Мощный процессор, 6 Gb памяти, отличная камера...   pos\n",
       "4  Яркий экран, отличное качество фото. Не обнару...   pos"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;p&gt;Хорошая камера, получаются четкие снимки в ...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;p&gt;Это мой четвертый Xiaomi, один лучше другог...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>безрамочный, цвета оч. сочные, камера 64, откл...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Мощный процессор, 6 Gb памяти, отличная камера...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Яркий экран, отличное качество фото. Не обнару...</td>\n      <td>pos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Очистка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данные попало много лишних тегов и прочего мусора. Для начала я уберу его, а также нормализую пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    _t = html.unescape(text)\n",
    "    _t = _t.replace(\"<p>\",\" \")\n",
    "    _t = _t.replace(\"</p>\", \" \")\n",
    "    _t = _t.replace(\"\\n\", \" \")\n",
    "    _t = _t.replace(\"\\r\", \" \")\n",
    "    _t = _t.replace(\"\\t\", \" \")\n",
    "    _t = _t.replace('\"', \"\")\n",
    "    return _t.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text_re(text):\n",
    "    _t = text\n",
    "    _t = _t.replace(\"   \",\" \")\n",
    "    _t = _t.replace(\"  \",\" \")\n",
    "    return _t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].apply(lambda x: normalize_text(x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: normalize_text_re(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10122    достоинство что это айфон)) уже. зарядка садит...\n",
       "10123    Удобство, качество агрегата, простота в исполь...\n",
       "10124    экран, скорость работы; внешний вид;размер; ка...\n",
       "10125    Аппарат показал себя на лучшем уровне. У моего...\n",
       "10126    Простота и удобство и даже тунец работает как ...\n",
       "10127    У меня было 4 blackberry. Все были на BB OS. З...\n",
       "10128    качественная сборка, качественное ПО. для того...\n",
       "10129          8 лет,а он все также работает!. нет. супер.\n",
       "10130    флеш карту принимает. удобный, лёгкий интерфей...\n",
       "10131    Качество связи. Динамик (и разговорный и внешн...\n",
       "10132    маленькии.уже есть опера это хорошо.аську можн...\n",
       "10133    мощный приём-передача. практически всё есть. у...\n",
       "10134    большие кнопки громкий звук фонарик длительная...\n",
       "10135    Удобный, приятный, лёгкий. Большие клавиши и х...\n",
       "10136    2 сим-карты; крупные цифры; голосовой набор; р...\n",
       "10137    большой экран, цена. 2 гнезда для наушников. к...\n",
       "10138    Нет люфта, клавиши нажимаются плавно. нет. Тел...\n",
       "10139    полный набор необходимых фукций, отличное каче...\n",
       "10140    хорош для тех у кого проблемы со зрением. цифр...\n",
       "10141    соответсвие цена-качество Лучшее. не удобные н...\n",
       "10142    В своей цене телефон качественный.... При испо...\n",
       "10143    1) Красивый внешний вид, оригинальный дизайн. ...\n",
       "10144    -цена -качество -алюминиевый корпус -камера -б...\n",
       "10145    Эргономичный, шустрый телефон. Хорошая камера....\n",
       "10146    Редкая модель. Полное отсутствие поддержки про...\n",
       "10147    это ежевика. нету. Предпочитаю физическую клав...\n",
       "10148    Лучший телефон в своем классе по всем параметр...\n",
       "10149    нет. камера.ботарейка.плохой сенсор очень тихи...\n",
       "10150    8 лет телефону, а батарея держит больше соврем...\n",
       "10151    размеры, звук, (правда с дугими наушниками), н...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "data[\"text\"].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Векторизация"
   ]
  },
  {
   "source": [
    "Я хочу воспользоваться библиотекой gensim, потому что я уже использовал их эмбеддинги, и они отлично показали себя в классификации, даже на плохо обработанном датасете.\n",
    "\n",
    "Чтобы потом удобно запаковать это в sklearn pipeline, я реализую свой класс по образу `TfIdfVectorizer` из `sklearn.feature_extraction`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import doc2vec\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import _VectorizerMixin\n",
    "import numpy as np\n",
    "\n",
    "class VectorizerTransformer(_VectorizerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        X = self.preprocess(raw_documents)\n",
    "        # print(\"Creating model...\")\n",
    "        model = gensim.models.doc2vec.Doc2Vec(\n",
    "            vector_size=60, \n",
    "            min_count=10,\n",
    "            epochs=40\n",
    "        )\n",
    "        # print(\"Building vocab...\")\n",
    "        model.build_vocab(X)\n",
    "        # print(\"Training doc2vec...\")\n",
    "        model.train(X, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "        self.model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        X = self.preprocess(raw_documents)\n",
    "        # print(\"Iinferring vectors...\")\n",
    "        vectorized_texts = []\n",
    "        for doc_id, _ in enumerate(tqdm(X, desc=\"Inferring vectors: \")):\n",
    "            inferred_vector = self.model.infer_vector(X[doc_id].words)\n",
    "            vectorized_texts.append(inferred_vector)\n",
    "\n",
    "        return vectorized_texts\n",
    "\n",
    "    def preprocess(self, raw_documents):\n",
    "        # print(\"Tokenization...\")\n",
    "        processed_texts = []\n",
    "        for idx, text in enumerate(tqdm(raw_documents, desc=\"Tokenization: \")):\n",
    "            processed_texts.append(doc2vec.TaggedDocument(simple_preprocess(text), [idx]))\n",
    "        return processed_texts\n",
    "\n",
    "\n",
    "    def fit_transform(self, texts, y=None) -> np.ndarray:\n",
    "        self.fit(texts)\n",
    "        X = self.transform(texts)\n",
    "        \n",
    "        return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обучение модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши данные не сбалансированны, потому для обучения модели применю андерсемплинг (потом)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.92565239, 0.92762186, 0.92807882, 0.92807882, 0.92463054])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "_model = make_pipeline(VectorizerTransformer(), GradientBoostingClassifier())\n",
    "\n",
    "cross_val_score(_model, data[\"text\"], data.label.map({\"pos\": 1, \"neg\": 0}), n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10152/10152 [00:00<00:00, 20614.83it/s]\n",
      "100%|██████████| 10152/10152 [00:00<00:00, 20892.57it/s]\n",
      "100%|██████████| 10152/10152 [00:20<00:00, 484.31it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizertransformer', VectorizerTransformer()),\n",
       "                ('gradientboostingclassifier', GradientBoostingClassifier())])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "_model.fit(data[\"text\"], data.label.map({\"pos\": 1, \"neg\": 0}))"
   ]
  },
  {
   "source": [
    "В принципе, качество уже не такое гадкое, можно попробовать сделать сабмит."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Инференс и подготовка сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "test = []\n",
    "with open(\"test.csv\") as tfile:\n",
    "    sp = bs4.BeautifulSoup(tfile)\n",
    "    revs = sp.findAll(\"review\")\n",
    "    for r in revs:\n",
    "        test.append(r.text)\n",
    "\n",
    "# pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 8538.20it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 269.89it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 5. Улучшение модели"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Улучшить модель можно несколькими путями:\n",
    "+ 1. Улучшить препроцессинг текста\n",
    "+ 2. Подобрать параметры модели векторизации\n",
    "+ 3. Подобрать параметры классификатора\n",
    "+ 4. Попробовать другие классификаторы\n",
    "\n",
    "Я сделаю только п.3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 6. Упаковка модели"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}